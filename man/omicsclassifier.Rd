% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/emethyl_clustering_new.R
\name{omicsclassifier}
\alias{omicsclassifier}
\title{Perform single-omic or multi-omics classification}
\usage{
omicsclassifier(
  dats,
  truelabels,
  varfeatures = NULL,
  scale = TRUE,
  balanceadj = 1,
  nround = 10,
  k = 5,
  nfold = 5,
  seednum = 2022,
  threads = 1,
  prescreen = TRUE,
  method = "SVM",
  C.base = 10,
  C.min = -3,
  C.max = -2,
  alphas = c(0.5),
  errortype = "min",
  crosstestacccut = 0.7,
  plot = TRUE,
  textsize = 13,
  prefixes = NULL
)
}
\arguments{
\item{dats}{A list with each element as each omic data of the samples to be
classified. Each omic data should be a matrix with columns as samples and
rows as features. The column names are the sample names and the row names
are the feature names.If only one omic data need to be classified, it need
to be a list with one element as the omic data matrix.}

\item{truelabels}{A vector with the sample class labels as elements. It can
use the sample names as the element names of the vector. If it does not
have element names, its element order should be consistent with the sample
order in all the omics data of \code{dats}.}

\item{varfeatures}{For each omic data in \code{dats}, the standard deviation
of the features can be calculated and the top variable features will be
selected and used for clustering. This parameter defines the number of the
top variable features will be selected. It should be an integer, such as
10000, so that the top 10000 most variable features of each omic will be
selected, and if the omic data have a feature number less than 10000, all
the features will be used. Can also be NULL, so that this variable feature
selection step will be skipped and all the omics will use all the features
for the classification. Default is NULL.}

\item{scale}{Whether the features of the omics need to be standardized, so
that all of them have a mean across all the samples as 0 and a standard
deviation of 1, and the classification will be performed after that. Its
default is TRUE.}

\item{balanceadj}{Before the elastic net feature selection and the SVM/MLR
model training steps, whether to construct an ensemble framework or not.
When this parameter is set as 1, a bagging-SMOTE (synthetic minority over-
sampling technique) ensemble framework will be constructed. In this case,
the sample distribution will be adjusted with bagging and SMOTE sampling
so that all the sample classes will have the same size, which prevents the
downstream model training from being influenced by any class sample size
imbalance. The model will have better accuracy in rare sample prediction.
When this parameter is set as 2, a normal bagging framework, rather than
the bagging-SMOTE one, will be constructed. The bagging framework is also
an ensemble one but it will not adjust the sample distribution. When this
parameter is set as 3, no ensemble framework will be constructed. In this
case, the ensemble step will be skipped and only the downstream elastic
net feature selection and SVM/MLR model training steps will be performed.
If the dataset is a single-omic one, the final prediction will be returned
after these steps. However, if the dataset is a multi-omics one, these
steps will be performed on each omic, respectively, and after all of them
return the prediction results for all the omics, a further ensemble step
will be used to aggregate them into the final one. The default value of
this paramter is 1.}

\item{nround}{When \code{balanceadj} is 1 or 2, this parameter will be used
to determine the number of the base learner sets in the ensemble-based
mode. Default is 10.}

\item{k}{When \code{balanceadj} is set as 1, this parameter will be used for
the SMOTE up-sampling step of the bagging-SMOTE framework, which works on
small sample classes and synthesizes new samples to increase their sample
number to the level of original total sample number/group number. It does
this from the closet neighbors of a randomly selected sample in the same
group, this parameter is used to define how many closet neighbors will be
needed. Default is 5, meaning the top 5 closet neighbors will be included
in synthesizing the new pseudo-sample.}

\item{nfold}{This parameter can be an integer and if it is greater than 1,
a cross validation will be performed and if the model achieves an accuracy
greater than the cutoff defined by the parameter \code{crosstestacccut},
the final model will be constructed from all the data transferred to the
parameter \code{dats}. If this parameter is the integer 1 or NULL, the
cross validation will be skipped and a model will be directly constructed
from the whole data. Default is 5, so a 5-fold cross validation will be
performed.}

\item{seednum}{The random seed number used for the elastic net regression to
define a 10-fold cross-validation, so an optimal regularization constant
lambda can be selected for the elastic net. It will also be used for the
balanced base learner sampling process and the cross validation dataset
generation process. Default is 2022.}

\item{threads}{Threads number for parallelization, default is 1.}

\item{prescreen}{When this parameter is set as TRUE, before starting the
formal training, a preliminary screen on the features will be performed
first with ANOVA so that only the features with an ANOVA p-val less than
0.05 on the response classes will be selected for the model training. Its
default value is TRUE.}

\item{method}{In the SVM/MLR model training step, which algorithm should be
used. Its value can be "SVM" or "MLR". Default is "SVM".}

\item{C.base}{A parameter special for the SVM model training step to set its
regularization constant. This constant will be calculated by the function
as base^index, and \code{C.base} here serves as the base number. Combined
with other 2 parameters \code{C.min} and \code{C.max} serving as indexes,
it will define a regularization constant series. The start value of this
series is \code{C.base}^\code{C.min}, and the end value of this series is
\code{C.base}^\code{C.max}, while the near elements of the series have a
difference of \code{C.base} fold. If the 2 indexes are set as the same,
the series will become 1 regularization constant. The default value of the
parameter \code{C.base} here is 10.}

\item{C.min}{As mentioned in the \code{C.base} part, this parameter is used
as the index of the small regularization constant number to set a series
for SVM. Default is -3.}

\item{C.max}{As mentioned in the \code{C.base} part, this parameter is used
as the index of the large regularization constant number to set a series
for SVM. Default is -2.}

\item{errortype}{The method to choose the regularization constant lambda for
the elastic net feature selection step. If it is set as "min", the lambda
that combines with \code{alpha} and gives the minimum mean 10-fold cross-
validation error will be used, and if it is set as "1ses", the lambda that
combines with \code{alpha} and gives the cross-validation error within one
standard error of the minimum will be used. The 10-fold cross-validation
is defined by the random seed \code{seednum}. For \code{errortype}, its
default value is "min".}

\item{crosstestacccut}{If a cross validation is performed as defined by the
parameter \code{nfold}, the cross validation accuracy on testing data need
to be greater than this \code{crossacccut}. Default value is 0.7. If it is
not reached, the function will return NULL.}

\item{plot}{Whether generate heatmap plots to show the sample classification
results.}

\item{textsize}{The font size of the plot texts. Default is 13.}

\item{prefixes}{The character string need to be shown in the titles of the
heatmap plots. It can be set as any character string need to be shown.
Default is NULL.}

\item{alpha}{The alpha parameter for elastic net feature selection, and it
controls the balance of L1 and L2 penalties. Default is 0.5.}
}
\value{
A list with a slot named "mod", which contains the final model from
the whole dataset. If cross validation is performed, an additional slot
named "cvtestcomps" will also be returned, which records the true labels
of the samples and their predicted labels when they are in testing dataset
during the cross validation.
}
\description{
Train single-omic or multi-omics classifiers via several steps, including
a data distribution adjustment step (optional), a elastic net feature
selection step, and an SVM or MLR model training step.
}
\examples{
library(CWGCNA)

betas <- system.file("extdata", "placentabetas.rds", package = "CWGCNA")
betas <- readRDS(betas)

pds <- system.file("extdata", "placentapds.rds", package = "CWGCNA")
pds <- readRDS(pds)

#Extract the DNAm probe data for the 101 preeclampsia samples
prepds <- subset(pds, Group == "Preeclampsia")
row.names(prepds) <- 1:nrow(prepds)

prebetas <- betas[, prepds$sampleid, drop = FALSE]

#Clustering
presubtyperes <- multiCCA(dats = list(prebetas), 
                         
 k = 2, consensus = 1, 
                         
 seednum = 2022, threads = 6, plot = TRUE, titlefix = "Preeclampsia", 
 titlesize = 18, textsize = 16)

#Make the sample labels from the clustering result
subtypes <- paste0("Subtype", presubtyperes$kreses$`k = 2`)

#Classification
\dontrun{
presubtypeclassifierres <- omicsclassifier(dats = list(prebetas), 
 truelabels = subtypes, 
                                          
 balanceadj = 1, 
                                          
 method = "SVM", 
                                          
 alphas = c(0.5), nfold = 5, 
                                          
 seednum = 2022, threads = 6, 
                                          
 plot = TRUE, prefixes = c("Preeclampsia (SVM-balance)"))
}



}
